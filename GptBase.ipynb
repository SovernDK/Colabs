{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"d7urm5nHgfVp"},"outputs":[],"source":["!pip3 install matplotlib numpy pylzma"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1708964177493,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"6GoJ38WKLCG7"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4m4bZTxb5kn"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","\n","batch_size = 64\n","block_size = 128\n","max_iters = 200\n","learning_rate = 3e-4\n","eval_iters = 100\n","n_embed = 384\n","n_head = 4\n","n_layer = 4\n","dropout = 0.2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1708964128652,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"cp5-mm6-cKiO"},"outputs":[],"source":["\n","#Replace this with bigger dataset (maybe some opensource corpus)\n","with open('Wizard of Oz.txt', 'r', encoding='utf-8') as f:\n","        text = f.read()\n","chars = sorted(set(text))\n","vocab_size = len(chars)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":501,"status":"ok","timestamp":1708964129145,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"eJSexnyzcKti"},"outputs":[],"source":["string_to_int = { ch:i for i,ch in enumerate(chars) }\n","int_to_string = { i:ch for i,ch in enumerate(chars) }\n","\n","encode = lambda s: [string_to_int[c] for c in s]\n","decode = lambda l: ''.join([int_to_string[i] for i in l])\n","\n","data = torch.tensor(encode(text), dtype=torch.long)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1708964130704,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"D6iYbvASeJdY"},"outputs":[],"source":["n = int(0.8*len(data))\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","def get_batch(split):\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","  x,y = x.to(device), y.to(device)\n","  return x, y\n","\n","x, y = get_batch('train')\n","# print('inputs: ')\n","# print(x)\n","# print('targets: ')\n","# print(y)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708964132352,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"fAE-e5FedYH-"},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","  out = {}\n","  model.eval()\n","  for split in ['train', 'val']:\n","    losses = torch.zeros(eval_iters)\n","    for k in range(eval_iters):\n","      X, Y = get_batch(split)\n","      logits, loss = model(X, Y)\n","      losses[k] = loss.item()\n","    out[split] = losses.mean()\n","  model.train()\n","  return out"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":367,"status":"ok","timestamp":1708964134359,"user":{"displayName":"Typowy Geek","userId":"09368889698903750967"},"user_tz":-60},"id":"Not5w1sJQzHb"},"outputs":[],"source":["class Head(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embed, head_size, bias=False)\n","    self.query = nn.Linear(n_embed, head_size, bias=False)\n","    self.value = nn.Linear(n_embed, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    B,T,C = x.shape\n","    k = self.key(x)\n","    q = self.query(x)\n","\n","    wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n","    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","    wei = F.softmax(wei, dim=-1)\n","    wei = self.dropout(wei)\n","\n","    v = self.value(x)\n","    out = wei @ v\n","    return out\n","\n","\n","class MultiHeadAttention(nn.Module):\n","  def __init__(self, num_heads, head_size):\n","    super().__init__()\n","    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","    self.proj = nn.Linear(head_size * num_heads, n_embed)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1) # (B,T,C) Cat along Channel(Features)\n","    out = self.dropout(self.proj(out))\n","    return out\n","\n","class FeedForward(nn.Module):\n","  def __init__(self, n_embed):\n","    super().__init__()\n","    self.net = nn.Sequential(nn.Linear(n_embed, 4 * n_embed),\n","                             nn.ReLU(),\n","                             nn.Linear(4 * n_embed, n_embed),\n","                             nn.Dropout(dropout))\n","\n","  def forward(self, x):\n","    return self.net(x)\n","\n","class Block(nn.Module):\n","  def __init__(self, n_embed, n_head):\n","    super().__init__()\n","    head_size = n_embed // n_head\n","    self.sa = MultiHeadAttention(n_head, head_size)\n","    self.ffwd = FeedForward(n_embed)\n","    self.ln1 = nn.LayerNorm(n_embed)\n","    self.ln2 = nn.LayerNorm(n_embed)\n","\n","  def forward(self, x):\n","    y = self.sa(x)\n","    x = self.ln1(x + y)\n","    y = self.ffwd(x)\n","    x = self.ln2(x + y)\n","    return x\n","\n","class GPTLanguageModel(nn.Module):\n","  def __init__(self, vocab_size):\n","    super().__init__()\n","    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n","    self.position_embedding_table = nn.Embedding(block_size, n_embed)\n","    self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n","    self.ln_f = nn.LayerNorm(n_embed)\n","    self.lm_head = nn.Linear(n_embed, vocab_size)\n","\n","    self.apply(self._init_weights)\n","\n","  def _init_weights(self, module):\n","    if isinstance(module, nn.Linear):\n","      torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","      if module.bias is not None:\n","        torch.nn.init.zeros_(module.bias)\n","      elif isinstance(module, nn.Embedding):\n","        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","  def forward(self, index, targets=None):\n","    B, T = index.shape\n","\n","    # idx and targets are both (B,T) tensor of integers\n","    tok_emb = self.token_embedding_table(index) #(B,T,C)\n","    pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #(T,C)\n","    x = tok_emb + pos_emb #(B,T,C)\n","    x = self.blocks(x) #(B,T,C)\n","    x = self.ln_f(x) #(B,T,C)\n","    logits = self.lm_head(x) #(B,T,vocab_size)\n","\n","    if targets is None:\n","      loss = None\n","    else:\n","      B, T, C = logits.shape\n","      logits = logits.view(B*T, C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","  def generate(self, index, max_new_tokens):\n","    for _ in range(max_new_tokens):\n","      logits, loss = self.forward(index)\n","      logits = logits[:,-1,:]\n","      probs = F.softmax(logits, dim=-1)\n","      index_next = torch.multinomial(probs, num_samples=1)\n","      index = torch.cat((index, index_next), dim = 1)\n","\n","    return index\n","\n","model = GPTLanguageModel(vocab_size)\n","m = model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBWzgIjmZkKV"},"outputs":[],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","  if iter % eval_iters == 0:\n","    losses = estimate_loss()\n","    print(f\"step: {iter}, train loss {losses['train']:.3f}, val loss {losses['val']:.3f}\")\n","\n","  xb, xy = get_batch('train')\n","\n","  logits, loss = model.forward(xb, xy)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","print(loss.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LtqIUQbseTCG"},"outputs":[],"source":["context = torch.zeros((1,1), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n","print(generated_chars)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPqTucjmstRuu3mMdprrj/x","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
